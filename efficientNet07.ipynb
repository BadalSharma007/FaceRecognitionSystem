{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tf_keras.utils import to_categorical\n",
    "\n",
    "# Download the full LFW dataset with all people included (no filtering)\n",
    "lfw_people=fetch_lfw_people(min_faces_per_person=0,resize=0.4,color=False)\n",
    "\n",
    "# Get the face images and labels\n",
    "data=lfw_people.images # face images\n",
    "labels=lfw_people.target # people\n",
    "target_names= lfw_people.target_names #list of all person names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 13233\n",
      "Image size : 50x37\n",
      "Number of classes (people) : 5749\n"
     ]
    }
   ],
   "source": [
    "#Print dataset details\n",
    "print(f\"Total images: {data.shape[0]}\")\n",
    "print(f\"Image size : {data.shape[1]}x{data.shape[2]}\") # heightxwidth\n",
    "print(f\"Number of classes (people) : {len(target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape : (10586, 50, 37, 1)\n",
      "Testing data shape: (2647, 50, 37, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape the data to include the channel dimension (for grayscale images, channel 1)\n",
    "data = data.reshape((data.shape[0], data.shape[1],data.shape[2],1))\n",
    "#split tha data\n",
    "x_train,x_test, y_train,y_test= train_test_split(data,labels,test_size=0.2,random_state=42)\n",
    "\n",
    "print(f\"Training data shape : {x_train.shape}\")\n",
    "print(f\"Testing data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tf_keras as tf\n",
    "from tf_keras import layers, Model\n",
    "\n",
    "def mb_conv_block(x,inputs,filters,kernel_size,strides,expand_ratio,se_ratio):\n",
    "    in_channels=x.shape[-1] # Number of inputs filters\n",
    "    expanded_filter=in_channels * expand_ratio\n",
    "    \n",
    "    #Expension phase\n",
    "    if expand_ratio != 1:\n",
    "        x =layers.Conv2D(expanded_filter,kernel_size=1, padding='same',use_bias=False)(x)\n",
    "        x=layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "    else:\n",
    "        x=x\n",
    "        \n",
    "    #Depthwise convolution\n",
    "    x=layers.DepthwiseConv2D(kernel_size,strides=strides,padding='same',use_bias=False)(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "    \n",
    "    # Squeeze and Excitation block\n",
    "    # if se_ratio:\n",
    "    #     se_shape=(1,1,in_channels * expand_ratio)\n",
    "    #     se=layers.GlobalAveragePooling2D()(x)\n",
    "    #     se=layers.Reshape(se_shape)(x)\n",
    "    #     se=layers.Dense(se_shape[-1]//4,activation='relu')(se)\n",
    "    #     se=layers.Dense(se_shape[-1],activation='sigmoid')(se)\n",
    "    #     x=layers.multiply([x,se])\n",
    "    \n",
    "    \n",
    "    if se_ratio:\n",
    "        in_channels = x.shape[-1]\n",
    "        se_shape = (1, 1, in_channels)\n",
    "        se = layers.GlobalAveragePooling2D()(x)  # This should output shape (None, in_channels)\n",
    "        se = layers.Reshape(se_shape)(se)  # Change this line to match the output shape\n",
    "        se = layers.Dense(in_channels // 4, activation='relu')(se)\n",
    "        se = layers.Dense(in_channels, activation='sigmoid')(se)\n",
    "        x = layers.multiply([x, se])  # Apply the squeeze-and-excitation weights\n",
    "\n",
    "        \n",
    "    #Output phase\n",
    "    x=layers.Conv2D(filters,kernel_size=1,padding='same',use_bias=False)(x)\n",
    "    x= layers.BatchNormalization()(x)\n",
    "    \n",
    "    if in_channels ==filters and strides ==1:\n",
    "        x=layers.add([x,inputs])\n",
    "        \n",
    "    return x          \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EfficientNetB7(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial Conv layer\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # MBConv Blocks following EfficientNetB7 architecture scaling\n",
    "    x = mb_conv_block(x, inputs=x, filters=32, kernel_size=3, strides=1, expand_ratio=1, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=32, kernel_size=3, strides=2, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=48, kernel_size=3, strides=2, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=48, kernel_size=3, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=80, kernel_size=5, strides=2, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=80, kernel_size=5, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=160, kernel_size=5, strides=2, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=160, kernel_size=5, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=224, kernel_size=5, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=224, kernel_size=5, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=384, kernel_size=3, strides=2, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=384, kernel_size=3, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    x = mb_conv_block(x, inputs=x, filters=640, kernel_size=3, strides=1, expand_ratio=6, se_ratio=0.25)\n",
    "    \n",
    "    # Final layers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)  # Adding dropout for EfficientNetB7\n",
    "    x = layers.Dense(2560, activation='relu')(x)  # Increased units as per EfficientNetB7\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model_3= Model(inputs, outputs)\n",
    "    return model_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (50, 37, 1)  # Set input shape to match the data\n",
    "model_3 = EfficientNetB7(input_shape=input_shape, num_classes=len(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "331/331 [==============================] - 43s 122ms/step - loss: 8.6510 - accuracy: 0.0376 - val_loss: 8.3090 - val_accuracy: 0.0366\n",
      "Epoch 2/5\n",
      "331/331 [==============================] - 38s 114ms/step - loss: 8.0835 - accuracy: 0.0404 - val_loss: 8.4094 - val_accuracy: 0.0363\n",
      "Epoch 3/5\n",
      "331/331 [==============================] - 38s 114ms/step - loss: 7.9422 - accuracy: 0.0398 - val_loss: 8.8004 - val_accuracy: 0.0366\n",
      "Epoch 4/5\n",
      "331/331 [==============================] - 38s 114ms/step - loss: 7.8668 - accuracy: 0.0409 - val_loss: 27.9810 - val_accuracy: 0.0366\n",
      "Epoch 5/5\n",
      "331/331 [==============================] - 38s 114ms/step - loss: 7.8514 - accuracy: 0.0409 - val_loss: 9.3611 - val_accuracy: 0.0359\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the resized data\n",
    "history_3 = model_3.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 2s 19ms/step - loss: 9.3611 - accuracy: 0.0359\n",
      "Test accuracy: 3.59%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_3.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model to a file\n",
    "# model_3.save('face_recognition_model3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data agumentation\n",
    "import numpy as np\n",
    "from tf_keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,         # Scale pixel values to [0, 1]\n",
    "    rotation_range=20,           # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,       # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,      # Randomly shift images vertically (fraction of total height)\n",
    "    shear_range=0.2,             # Shear transformation\n",
    "    zoom_range=0.2,              # Randomly zoom into images\n",
    "    horizontal_flip=True,         # Randomly flip images\n",
    "    fill_mode='nearest',          # Fill in new pixels after rotation or width/height shifts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator for the training data\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.models import clone_model\n",
    "model_4=tf.models.clone_model(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "330/330 [==============================] - 189s 566ms/step - loss: 8.2729 - accuracy: 0.0260 - val_loss: 8.5366 - val_accuracy: 0.0087\n",
      "Epoch 2/10\n",
      "330/330 [==============================] - 168s 511ms/step - loss: 7.9446 - accuracy: 0.0332 - val_loss: 13919.2158 - val_accuracy: 0.0087\n",
      "Epoch 3/10\n",
      "330/330 [==============================] - 178s 541ms/step - loss: 7.8845 - accuracy: 0.0307 - val_loss: 467.9318 - val_accuracy: 0.0015\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 1552s 5s/step - loss: 7.8307 - accuracy: 0.0329 - val_loss: 14578.7520 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 100s 303ms/step - loss: 7.7489 - accuracy: 0.0335 - val_loss: 50303.6523 - val_accuracy: 0.0064\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 39s 117ms/step - loss: 7.7122 - accuracy: 0.0337 - val_loss: 27643.6934 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tf_keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history_2 = model_4.fit(train_generator, steps_per_epoch=len(x_train)//32, epochs=10, validation_data=(x_test,y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_2= model_4.fit(train_generator,steps_per_epoch=len(x_train)//32, epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 2s 19ms/step - loss: 8.5366 - accuracy: 0.0087\n",
      "Test accuracy: 0.87%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_4.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent training accuracy: 3.37%\n",
      "Most recent validation accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Access accuracy from the training history\n",
    "train_accuracy = history_2.history['accuracy']\n",
    "val_accuracy = history_2.history['val_accuracy']\n",
    "\n",
    "# Print the most recent training and validation accuracy\n",
    "print(f\"Most recent training accuracy: {train_accuracy[-1] * 100:.2f}%\")\n",
    "print(f\"Most recent validation accuracy: {val_accuracy[-1] * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
